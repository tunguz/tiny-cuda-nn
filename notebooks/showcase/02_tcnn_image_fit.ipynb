{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03c7bab4",
   "metadata": {},
   "source": [
    "# Image Fit With PyTorch Binding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7121c8c",
   "metadata": {},
   "source": [
    "A compact variant of the image-learning demo (`samples/mlp_learning_an_image_pytorch.py`).\n",
    "It trains on random UV samples from `data/images/albert.jpg` and verifies reconstruction error improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42331deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository root: /media/tunguz/3139-3535/tiny-cuda-nn\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import tinycudann as tcnn\n",
    "from PIL import Image\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    for p in [start, *start.parents]:\n",
    "        if (p / \"README.md\").exists() and (p / \"CMakeLists.txt\").exists():\n",
    "            return p\n",
    "    raise RuntimeError(\"Could not find tiny-cuda-nn repository root.\")\n",
    "\n",
    "ROOT = find_repo_root(Path.cwd().resolve())\n",
    "print(\"Repository root:\", ROOT)\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\"CUDA is required for tinycudann examples.\")\n",
    "\n",
    "torch.manual_seed(13)\n",
    "np.random.seed(13)\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "708c1ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded image: /media/tunguz/3139-3535/tiny-cuda-nn/data/images/albert.jpg (3250x4333)\n"
     ]
    }
   ],
   "source": [
    "image_path = ROOT / \"data\" / \"images\" / \"albert.jpg\"\n",
    "img_np = np.asarray(Image.open(image_path).convert(\"RGB\"), dtype=np.float32) / 255.0\n",
    "img = torch.from_numpy(img_np).to(device)\n",
    "height, width, _ = img.shape\n",
    "\n",
    "print(f\"Loaded image: {image_path} ({width}x{height})\")\n",
    "\n",
    "config = json.loads((ROOT / \"data\" / \"config_hash.json\").read_text(encoding=\"utf-8\"))\n",
    "model = tcnn.NetworkWithInputEncoding(\n",
    "    n_input_dims=2,\n",
    "    n_output_dims=3,\n",
    "    encoding_config=config[\"encoding\"],\n",
    "    network_config=config[\"network\"],\n",
    ").to(device)\n",
    "model.jit_fusion = tcnn.supports_jit_fusion()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bace864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_image(coords: torch.Tensor) -> torch.Tensor:\n",
    "    # coords: [N, 2] in [0, 1], with columns (x, y)\n",
    "    xs = coords[:, 0] * (width - 1)\n",
    "    ys = coords[:, 1] * (height - 1)\n",
    "\n",
    "    x0 = torch.floor(xs).long().clamp(0, width - 1)\n",
    "    y0 = torch.floor(ys).long().clamp(0, height - 1)\n",
    "    x1 = (x0 + 1).clamp(max=width - 1)\n",
    "    y1 = (y0 + 1).clamp(max=height - 1)\n",
    "\n",
    "    wx = (xs - x0.float()).unsqueeze(1)\n",
    "    wy = (ys - y0.float()).unsqueeze(1)\n",
    "\n",
    "    c00 = img[y0, x0]\n",
    "    c10 = img[y0, x1]\n",
    "    c01 = img[y1, x0]\n",
    "    c11 = img[y1, x1]\n",
    "\n",
    "    return (\n",
    "        c00 * (1.0 - wx) * (1.0 - wy)\n",
    "        + c10 * wx * (1.0 - wy)\n",
    "        + c01 * (1.0 - wx) * wy\n",
    "        + c11 * wx * wy\n",
    "    )\n",
    "\n",
    "\n",
    "def evaluate_full_image_mse() -> float:\n",
    "    with torch.no_grad():\n",
    "        xs = torch.linspace(0.0, 1.0, width, device=device)\n",
    "        ys = torch.linspace(0.0, 1.0, height, device=device)\n",
    "        yy, xx = torch.meshgrid(ys, xs, indexing=\"ij\")\n",
    "        coords = torch.stack([xx.reshape(-1), yy.reshape(-1)], dim=1)\n",
    "        pred = model(coords).reshape(height, width, 3).clamp(0.0, 1.0)\n",
    "        return torch.mean((pred - img) ** 2).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ce7c78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tiny-cuda-nn warning: /media/tunguz/3139-3535/tiny-cuda-nn/src/rtc_kernel.cu:305 cuModuleLoadDataEx(&m_module, ptx.data(), 0, nullptr, nullptr) failed: CUDA_ERROR_UNSUPPORTED_PTX_VERSION\n",
      "Failed to JIT-compile `inference_mp_network_with_input_encoding`. Disabling JIT.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full-image MSE before training: 0.222253\n",
      "step=000 mse=0.221711\n",
      "step=019 mse=0.010469\n",
      "step=039 mse=0.004558\n",
      "step=059 mse=0.003020\n",
      "step=079 mse=0.002450\n",
      "step=099 mse=0.001875\n",
      "step=119 mse=0.001596\n",
      "full-image MSE after training:  0.001681\n",
      "final PSNR: 27.74 dB\n"
     ]
    }
   ],
   "source": [
    "start_mse = evaluate_full_image_mse()\n",
    "print(f\"full-image MSE before training: {start_mse:.6f}\")\n",
    "\n",
    "steps = 120\n",
    "batch_size = 16384\n",
    "for step in range(steps):\n",
    "    coords = torch.rand((batch_size, 2), device=device)\n",
    "    target = sample_image(coords)\n",
    "    pred = model(coords)\n",
    "    loss = torch.mean((pred - target) ** 2)\n",
    "\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step in {0, 19, 39, 59, 79, 99, 119}:\n",
    "        print(f\"step={step:03d} mse={float(loss.item()):.6f}\")\n",
    "\n",
    "end_mse = evaluate_full_image_mse()\n",
    "psnr = -10.0 * math.log10(max(end_mse, 1e-12))\n",
    "print(f\"full-image MSE after training:  {end_mse:.6f}\")\n",
    "print(f\"final PSNR: {psnr:.2f} dB\")\n",
    "\n",
    "assert end_mse < start_mse, \"Image training did not improve reconstruction error.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34140925-dbfe-4e09-ae8d-983f50b634d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
